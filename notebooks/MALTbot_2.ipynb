{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcYuT2wsrjgX"
      },
      "source": [
        "# MALTbot \u2014 Daily Colab Batch Runner (canonical)\n",
        "\n",
        "## \uc6d0\ud558\ub294 UX (\uc0ac\uc6a9\uc790 \uae30\uc900)\n",
        "1) Colab\uc5d0\uc11c `notebooks/MALTbot_2.ipynb` \uc5f4\uae30\n",
        "2) \ub9e8 \uc704 **CONFIG \uc140\ub9cc** \uc218\uc815\n",
        "   - `BATCH_RUN_NAME`: \uc608) `2026-02-21_batch1`\n",
        "   - `EXPERIMENTS`: \uc608) `[\"baseline_chgnet\", \"chgnet_seed43\", \"chgnet_lr_schedule\", ...]`\n",
        "   - (\uc635\uc158) `GH_PUSH=True/False`\n",
        "3) **Run all**\n",
        "\n",
        "\uc2e4\ud589 \ud6c4 \uc790\ub3d9\uc73c\ub85c:\n",
        "- `results/daily/<DATE>/<BATCH_RUN_NAME>/<exp_name>/results.json` \uc0dd\uc131 (\uc2e4\ud5d8\ubcc4 1\uac1c)\n",
        "- `RESULTS.md`\uc5d0 \uc2e4\ud5d8\ubcc4 1\uc904 append\n",
        "- GitHub\uc5d0 \ube0c\ub79c\uce58 `colab-<DATE>-<SAFE_BATCH>`\ub85c \ud55c \ubc88\uc5d0 push + PR \ub9c1\ud06c \ucd9c\ub825\n",
        "\n",
        "> \uc6d0\uce59: `main`\uc5d0 \uc9c1\uc811 push\ud558\uc9c0 \uc54a\uace0, PR\ub85c\ub9cc \ubc18\uc601.\n"
      ],
      "id": "WcYuT2wsrjgX"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6fIj6-HXrjgb",
        "outputId": "238eb6c8-6f87-49ec-c50b-7abb85c13120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12\n",
            "Torch: 2.10.0+cu128\n",
            "CUDA available: True\n",
            "GPU: NVIDIA L4\n"
          ]
        }
      ],
      "source": "\nimport platform\nprint(\"Python:\", platform.python_version())\ntry:\n    import torch\n    print(\"Torch:\", torch.__version__)\n    print(\"CUDA available:\", torch.cuda.is_available())\n    print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\nexcept Exception as e:\n    print(\"[warn] torch import failed:\", repr(e))\n    print(\"[action] Run the torch repair/install cell below, then re-run this cell.\")\n",
      "id": "6fIj6-HXrjgb"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vcdSCdj6rjgc",
        "outputId": "b26c4609-4602-4651-d6b1-b3ac856fbb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-101662561.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    from pathlib import Path\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    if not Path('/content/drive/MyDrive').exists():\n",
        "        raise RuntimeError(\"Drive mount path not found.\")\n",
        "    print(\"Drive mounted: /content/drive/MyDrive\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] Drive mount failed: {e}\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(\"[FIX] If you see 'credential propagation' error:\")\n",
        "    print(\"1. Refresh this page (F5).\")\n",
        "    print(\"2. Go to Runtime -> Disconnect and delete runtime.\")\n",
        "    print(\"3. Click 'Run all' again and accept the popup.\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    raise e\n"
      ],
      "id": "vcdSCdj6rjgc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom google.colab import userdata\nimport os\n\n# GH_PUSH policy upfront (change to \"0\" to disable push workflow)\nos.environ.setdefault(\"MALTBOT_GH_PUSH\", \"1\")\nprint(f\"GH_PUSH(default): {os.environ.get('MALTBOT_GH_PUSH')} (1=enabled, 0=disabled)\")\n\nif os.environ.get(\"MALTBOT_GH_PUSH\") == \"1\":\n    raw = userdata.get(\"GH_TOKEN\")\n    token = raw if isinstance(raw, str) and raw.strip() else None\n    if not token:\n        raise RuntimeError(\n            \"GH_TOKEN not found in Colab Secrets.\\n\"\n            \"Steps: Left sidebar -> Secrets -> Add key 'GH_TOKEN' with repo push scope -> rerun this cell.\"\n        )\n    os.environ[\"GH_TOKEN\"] = token.strip()\n    print(\"GH_TOKEN loaded from Colab Secrets (hidden)\")\nelse:\n    print(\"GH_PUSH=0: token check skipped\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xc7U-SCXrjgb",
        "outputId": "10c3e55a-e269-47df-e0e4-0c77839832ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] Cloning repo...\n",
            "f422ccf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into '/content/MALTbot'...\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "REPO_DIR=\"/content/MALTbot\"\n",
        "REPO_URL=\"https://github.com/seanwoory/MALTbot.git\"\n",
        "\n",
        "if [ -d \"${REPO_DIR}/.git\" ]; then\n",
        "  echo \"[info] Repo exists. Force sync to origin/main...\"\n",
        "  cd \"${REPO_DIR}\"\n",
        "  git fetch origin\n",
        "  git checkout main || true\n",
        "  git reset --hard origin/main\n",
        "else\n",
        "  echo \"[info] Cloning repo...\"\n",
        "  git clone \"${REPO_URL}\" \"${REPO_DIR}\"\n",
        "  cd \"${REPO_DIR}\"\n",
        "  git checkout main || true\n",
        "fi\n"
      ],
      "id": "xc7U-SCXrjgb"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FMHv8fuArjga",
        "outputId": "f45f82c2-825a-4b32-e50b-df545a1b55a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'DATE': '2026-02-23', 'BATCH_RUN_NAME(raw)': 'daily10', 'SAFE_BATCH': 'daily10', 'TASK': 'matbench_mp_e_form', 'EXPERIMENTS': ['chgnet_pretrained_infer', 'chgnet_head_finetune_freeze', 'chgnet_full_finetune', 'chgnet_ensemble3', 'mlp_pretrained_infer_fallback', 'mlp_head_finetune_freeze', 'chgnet_seed43', 'chgnet_seed44', 'chgnet_lr_schedule', 'chgnet_target_transform', 'chgnet_ema', 'chgnet_epochs80_seed43'], 'GH_PUSH': True}\n"
          ]
        }
      ],
      "source": "\n# --- Quick UX ---\n# \uc544\ub798 \ubcc0\uc218\ub9cc \ubc14\uafb8\uace0 Run all:\n#   - BATCH_RUN_NAME: \uc608) 2026-02-21_batch1\n#   - EXPERIMENTS: \uc608) [\"baseline_chgnet\", \"chgnet_seed43\", ...]\n#   - GH_PUSH: True\uba74 \uc790\ub3d9 push + PR \ub9c1\ud06c \ucd9c\ub825\n# \uc2e4\ud589 \ud6c4 \uc790\ub3d9\uc73c\ub85c:\n#   - results/daily/<DATE>/<SAFE_BATCH>/<exp_name>/results.json \uc0dd\uc131\n#   - RESULTS.md\uc5d0 \uc2e4\ud5d8\ubcc4 1\uc904 append\n#   - GitHub \ube0c\ub79c\uce58 colab-<DATE>-<SAFE_BATCH>\ub85c push\n# ----------------\n\n# CONFIG (edit only this cell)\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nimport os, re, uuid\n\nDATE = datetime.now(ZoneInfo(\"Asia/Seoul\")).strftime(\"%Y-%m-%d\")\nBATCH_RUN_NAME = \"daily11_alignn\"\nTASK = \"matbench_mp_e_form\"\nEXPERIMENTS = [\n    \"alignn_fold0_agile\",\n]\nGH_PUSH = True\n\n# Two-tier run mode: \"SMOKE\" (ultra-fast) or \"FULL\" (deeper)\nRUN_MODE = \"FULL\"\nSMOKE_FRACTION = 0.0001\nFULL_FRACTION = 0.1\nSMOKE_EPOCHS = 1\nFULL_EPOCHS = 3\nSMOKE_PATIENCE = 1\nFULL_PATIENCE = 3\nSMOKE_BATCH_SIZE = 4\nFULL_BATCH_SIZE = 8\n# Cache fraction can be decoupled from data fraction (e.g., 0.001 agile cache, 1.0 official cache)\nCACHE_FRACTION = 0.001\nFOLDS = [\"fold_0\"]\nRUN_ID = uuid.uuid4().hex[:8]\n\nSAFE_BATCH = re.sub(r\"[^A-Za-z0-9._-]+\", \"-\", BATCH_RUN_NAME).strip(\"-\") or \"batch\"\n\nos.environ[\"MALTBOT_DATE\"] = DATE\nos.environ[\"MALTBOT_BATCH_RUN_NAME\"] = SAFE_BATCH\nos.environ[\"MALTBOT_TASK\"] = TASK\nos.environ[\"MALTBOT_EXPERIMENTS\"] = \",\".join(EXPERIMENTS)\nos.environ[\"MALTBOT_GH_PUSH\"] = \"1\" if GH_PUSH else \"0\"\nos.environ[\"MALTBOT_RUN_MODE\"] = RUN_MODE\nos.environ[\"MALTBOT_SMOKE_FRACTION\"] = str(SMOKE_FRACTION)\nos.environ[\"MALTBOT_FULL_FRACTION\"] = str(FULL_FRACTION)\nos.environ[\"MALTBOT_SMOKE_EPOCHS\"] = str(SMOKE_EPOCHS)\nos.environ[\"MALTBOT_FULL_EPOCHS\"] = str(FULL_EPOCHS)\nos.environ[\"MALTBOT_SMOKE_PATIENCE\"] = str(SMOKE_PATIENCE)\nos.environ[\"MALTBOT_FULL_PATIENCE\"] = str(FULL_PATIENCE)\nos.environ[\"MALTBOT_SMOKE_BATCH_SIZE\"] = str(SMOKE_BATCH_SIZE)\nos.environ[\"MALTBOT_FULL_BATCH_SIZE\"] = str(FULL_BATCH_SIZE)\nos.environ[\"MALTBOT_CACHE_FRACTION\"] = str(CACHE_FRACTION)\nos.environ[\"MALTBOT_FOLDS\"] = \",\".join(FOLDS)\nos.environ[\"MALTBOT_RUN_ID\"] = RUN_ID\n\nprint({\n    \"DATE\": DATE,\n    \"BATCH_RUN_NAME(raw)\": BATCH_RUN_NAME,\n    \"SAFE_BATCH\": SAFE_BATCH,\n    \"TASK\": TASK,\n    \"EXPERIMENTS\": EXPERIMENTS,\n    \"GH_PUSH\": GH_PUSH,\n    \"RUN_MODE\": RUN_MODE,\n    \"SMOKE_FRACTION\": SMOKE_FRACTION,\n    \"FULL_FRACTION\": FULL_FRACTION,\n    \"SMOKE_EPOCHS\": SMOKE_EPOCHS,\n    \"FULL_EPOCHS\": FULL_EPOCHS,\n    \"SMOKE_BATCH_SIZE\": SMOKE_BATCH_SIZE,\n    \"FULL_BATCH_SIZE\": FULL_BATCH_SIZE,\n    \"CACHE_FRACTION\": CACHE_FRACTION,\n    \"FOLDS\": FOLDS,\n    \"RUN_ID\": RUN_ID,\n})\n",
      "id": "FMHv8fuArjga"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xPIOPWjUrjgZ",
        "outputId": "983de6ea-cd2c-437d-e427-2b7d6d34c037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.10.0+cu128)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch) (1.3.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# [FIX] Force reinstall torch to resolve Colab Python 3.12 circular import error\n",
        "!pip install --upgrade torch --index-url https://download.pytorch.org/whl/cu121"
      ],
      "id": "xPIOPWjUrjgZ"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KlOiQIAUrjgb",
        "outputId": "7742b08b-2646-44dd-ef5e-b7fe69dbd0c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process is terminated.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "LOG=/tmp/maltbot_pip_install.log\n",
        "echo \"[info] Starting FIXED GOLDEN recipe install...\" > \"$LOG\"\n",
        "\n",
        "install_pkg() {\n",
        "  echo \"[installing] $*\" >> \"$LOG\"\n",
        "  if ! python3 -m pip install --no-cache-dir \"$@\" >> \"$LOG\" 2>&1; then\n",
        "    echo \"[ERROR] Failed to install: $*\"\n",
        "    tail -n 20 \"$LOG\"\n",
        "    exit 1\n",
        "  fi\n",
        "}\n",
        "\n",
        "install_pkg \"pip>=24.0\" \"setuptools>=69.0\" \"wheel\"\n",
        "install_pkg \"numpy==1.26.4\"\n",
        "install_pkg \"scikit-learn==1.4.1.post1\"\n",
        "install_pkg \"matminer==0.9.2\"\n",
        "install_pkg \"matbench==0.6\"  # Fixed from hallucinated 0.1.6\n",
        "install_pkg \"dgl==2.1.0+cu121\" \"-f\" \"https://data.dgl.ai/wheels/cu121/repo.html\"\n",
        "install_pkg \"alignn==2024.3.21\" \"jarvis-tools\" \"chgnet\"\n",
        "\n",
        "echo \"[ok] FINAL FIXED RECIPE applied\"\n"
      ],
      "id": "KlOiQIAUrjgb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgl_alignn_import_check"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import collections, collections.abc, sys, importlib, subprocess\n",
        "# Comprehensive collections patch\n",
        "for name in ['Mapping', 'MutableMapping', 'Iterable', 'Sequence', 'Callable', 'Iterator']:\n",
        "    if not hasattr(collections, name):\n",
        "        setattr(collections, name, getattr(collections.abc, name))\n",
        "\n",
        "def ensure_final(pkg, install_cmd):\n",
        "    try:\n",
        "        importlib.import_module(pkg)\n",
        "        print(f\"[ok] {pkg} is ready\")\n",
        "    except Exception as e:\n",
        "        print(f\"[critical] {pkg} verification failed: {e!r}\")\n",
        "        print(f\"[action] Attempting emergency install for {pkg}...\")\n",
        "        subprocess.check_call(install_cmd)\n",
        "        importlib.invalidate_caches()\n",
        "        importlib.import_module(pkg)\n",
        "        print(f\"[ok] {pkg} is now ready after emergency install\")\n",
        "\n",
        "ensure_final(\"matbench\", [sys.executable, \"-m\", \"pip\", \"install\", \"matbench\"])\n",
        "ensure_final(\"dgl\", [sys.executable, \"-m\", \"pip\", \"install\", \"dgl\", \"-f\", \"https://data.dgl.ai/wheels/cu121/repo.html\"])\n",
        "ensure_final(\"alignn\", [sys.executable, \"-m\", \"pip\", \"install\", \"alignn\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BDivp03Grjgc",
        "outputId": "99521ff6-d54e-455f-c5f7-61dbecfa7285",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] Install debug skipped (no failure marker).\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "LOG=/tmp/maltbot_pip_install.log\n",
        "echo \"[info] Starting FIXED GOLDEN recipe install...\" > \"$LOG\"\n",
        "\n",
        "install_pkg() {\n",
        "  echo \"[installing] $*\" >> \"$LOG\"\n",
        "  if ! python3 -m pip install --no-cache-dir \"$@\" >> \"$LOG\" 2>&1; then\n",
        "    echo \"[ERROR] Failed to install: $*\"\n",
        "    tail -n 20 \"$LOG\"\n",
        "    exit 1\n",
        "  fi\n",
        "}\n",
        "\n",
        "install_pkg \"pip>=24.0\" \"setuptools>=69.0\" \"wheel\"\n",
        "install_pkg \"numpy==1.26.4\"\n",
        "install_pkg \"scikit-learn==1.4.1.post1\"\n",
        "install_pkg \"matminer==0.9.2\"\n",
        "install_pkg \"matbench==0.6\"  # Fixed from hallucinated 0.1.6\n",
        "install_pkg \"dgl==2.1.0+cu121\" \"-f\" \"https://data.dgl.ai/wheels/cu121/repo.html\"\n",
        "install_pkg \"alignn==2024.3.21\" \"jarvis-tools\" \"chgnet\"\n",
        "\n",
        "echo \"[ok] FINAL FIXED RECIPE applied\"\n"
      ],
      "id": "BDivp03Grjgc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I34tk2lKrjgc"
      },
      "outputs": [],
      "source": "\nimport os, subprocess, sys, time\n\nrepo = \"/content/MALTbot\"\nexperiments = [x.strip() for x in os.environ.get(\"MALTBOT_EXPERIMENTS\", \"\").split(\",\") if x.strip()]\nif not experiments:\n    raise ValueError(\"EXPERIMENTS is empty\")\n\ngh_push = os.environ.get(\"MALTBOT_GH_PUSH\") == \"1\"\ndate = os.environ.get(\"MALTBOT_DATE\")\nbatch = os.environ.get(\"MALTBOT_BATCH_RUN_NAME\")\nrun_id = os.environ.get(\"MALTBOT_RUN_ID\", \"run\")\nbranch = f\"colab-{date}-{batch}-{run_id}\" if date and batch else None\nstop_on_push_fail = os.environ.get(\"MALTBOT_STOP_ON_PUSH_FAIL\", \"1\") == \"1\"\n\n\ndef run_cmd(cmd, check=False, capture=False):\n    return subprocess.run(\n        cmd,\n        cwd=repo,\n        check=check,\n        text=True,\n        capture_output=capture,\n    )\n\n\ndef push_with_recovery(base_branch: str):\n    # path A: normal push\n    push = run_cmd([\"git\", \"push\", \"-u\", \"origin\", base_branch], capture=True)\n    if push.returncode == 0:\n        print(f\"[push] success: {base_branch}\")\n        return True, base_branch\n\n    print(f\"[push] first attempt failed for {base_branch}\")\n    if push.stdout:\n        print(\"[push stdout]\", push.stdout[-1200:])\n    if push.stderr:\n        print(\"[push stderr]\", push.stderr[-1200:])\n\n    # path B: fetch + rebase + retry\n    print(f\"[push] recovery path A: fetch+rebase+retry ({base_branch})\")\n    run_cmd([\"git\", \"fetch\", \"origin\", base_branch], capture=True)\n    rb = run_cmd([\"git\", \"rebase\", f\"origin/{base_branch}\"], capture=True)\n    if rb.returncode != 0:\n        run_cmd([\"git\", \"rebase\", \"--abort\"], capture=True)\n        print(\"[push] rebase failed; trying fallback branch\")\n\n    push2 = run_cmd([\"git\", \"push\", \"-u\", \"origin\", base_branch], capture=True)\n    if push2.returncode == 0:\n        print(f\"[push] recovery A success: {base_branch}\")\n        return True, base_branch\n\n    # path C: fallback unique branch\n    fallback = f\"{base_branch}-r{int(time.time())}\"\n    print(f\"[push] recovery path B: fallback branch {fallback}\")\n    run_cmd([\"git\", \"checkout\", \"-B\", fallback], capture=True)\n    push3 = run_cmd([\"git\", \"push\", \"-u\", \"origin\", fallback], capture=True)\n    if push3.returncode == 0:\n        print(f\"[push] recovery B success: {fallback}\")\n        print(f\"[push] PR URL: https://github.com/seanwoory/MALTbot/compare/main...{fallback}?expand=1\")\n        return True, fallback\n\n    print(\"[push] recovery failed\")\n    if push3.stdout:\n        print(\"[push3 stdout]\", push3.stdout[-1200:])\n    if push3.stderr:\n        print(\"[push3 stderr]\", push3.stderr[-1200:])\n    return False, base_branch\n\n\nif gh_push:\n    token = os.environ.get(\"GH_TOKEN\", \"\")\n    if not token:\n        raise ValueError(\"GH_PUSH=True but GH_TOKEN is not set\")\n    run_cmd([\"git\", \"checkout\", \"-B\", branch], check=False)\n    run_cmd([\"git\", \"config\", \"user.name\", \"colab-bot\"], check=True)\n    run_cmd([\"git\", \"config\", \"user.email\", \"colab-bot@users.noreply.github.com\"], check=True)\n    run_cmd([\"git\", \"remote\", \"set-url\", \"origin\", f\"https://{token}@github.com/seanwoory/MALTbot.git\"], check=True)\n\nfor exp in experiments:\n    print(f\"\\n===== RUN {exp} =====\")\n    cmd = [sys.executable, \"scripts/run_experiment.py\", \"--exp-name\", exp]\n\n    proc = subprocess.Popen(\n        cmd,\n        cwd=repo,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n        bufsize=1,\n    )\n\n    out_lines = []\n    assert proc.stdout is not None\n    for line in proc.stdout:\n        print(line, end=\"\")\n        out_lines.append(line)\n\n    return_code = proc.wait()\n    print(f\"status code: {return_code}\")\n\n    if gh_push and branch:\n        exp_path = f\"results/daily/{date}/{batch}/{exp}/results.json\"\n        run_cmd([\"git\", \"add\", exp_path, \"RESULTS.md\"], check=False)\n        diff = run_cmd([\"git\", \"diff\", \"--cached\", \"--quiet\"], check=False)\n        if diff.returncode != 0:\n            msg = f\"results: {exp}\"\n            run_cmd([\"git\", \"commit\", \"-m\", msg], check=False)\n            ok, used_branch = push_with_recovery(branch)\n            if not ok and stop_on_push_fail:\n                raise RuntimeError(\"Push failed after all recovery paths and STOP_ON_PUSH_FAIL=True\")\n            if used_branch != branch:\n                branch = used_branch\n        else:\n            print(f\"[no changes] {exp}\")\n\nprint(\"Batch finished\")\n",
      "id": "I34tk2lKrjgc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNWn4oyVrjgd"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "cd /content/MALTbot\n",
        "find \"results/daily/${MALTBOT_DATE}/${MALTBOT_BATCH_RUN_NAME}\" -type f -name \"results.json\" | sort || true\n",
        "tail -n 20 RESULTS.md\n"
      ],
      "id": "sNWn4oyVrjgd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHo8N-y1rjgd"
      },
      "outputs": [],
      "source": "\nprint(\"Token already checked upfront. Skipping duplicate token prompt.\")\n",
      "id": "PHo8N-y1rjgd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu2uLdGbrjgd"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "cd /content/MALTbot\n",
        "\n",
        "if [ \"${MALTBOT_GH_PUSH}\" != \"1\" ]; then\n",
        "  echo \"GH_PUSH=False; skip preflight\"\n",
        "  exit 0\n",
        "fi\n",
        "\n",
        ": \"${GH_TOKEN:?GH_TOKEN is not set}\"\n",
        ": \"${MALTBOT_DATE:?MALTBOT_DATE missing}\"\n",
        ": \"${MALTBOT_BATCH_RUN_NAME:?MALTBOT_BATCH_RUN_NAME missing}\"\n",
        "\n",
        "BRANCH=\"colab-${MALTBOT_DATE}-${MALTBOT_BATCH_RUN_NAME}\"\n",
        "\n",
        "git checkout -B \"${BRANCH}\" >/dev/null 2>&1 || git checkout \"${BRANCH}\" >/dev/null 2>&1\n",
        "\n",
        "git remote set-url origin \"https://${GH_TOKEN}@github.com/seanwoory/MALTbot.git\"\n",
        "\n",
        "echo \"Preflight OK: token set, origin updated, branch=${BRANCH}\"\n"
      ],
      "id": "Nu2uLdGbrjgd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhrz6Wijrjgd"
      },
      "outputs": [],
      "source": "\n%%bash\nset -euo pipefail\ncd /content/MALTbot\n\nif [ \"${MALTBOT_GH_PUSH}\" != \"1\" ]; then\n  echo \"GH_PUSH=False; skip git push\"\n  exit 0\nfi\n\n: \"${GH_TOKEN:?GH_TOKEN is not set}\"\n: \"${MALTBOT_DATE:?MALTBOT_DATE missing}\"\n: \"${MALTBOT_BATCH_RUN_NAME:?MALTBOT_BATCH_RUN_NAME missing}\"\n\nRUN_ID=\"${MALTBOT_RUN_ID:-run}\"\nBRANCH=\"colab-${MALTBOT_DATE}-${MALTBOT_BATCH_RUN_NAME}-${RUN_ID}\"\n\ngit config user.name \"colab-bot\"\ngit config user.email \"colab-bot@users.noreply.github.com\"\ngit checkout -B \"${BRANCH}\"\ngit remote set-url origin \"https://${GH_TOKEN}@github.com/seanwoory/MALTbot.git\"\n\ngit add \"results/daily/${MALTBOT_DATE}/${MALTBOT_BATCH_RUN_NAME}\" RESULTS.md || true\nif ! git diff --cached --quiet; then\n  git commit -m \"results: ${MALTBOT_DATE} ${MALTBOT_BATCH_RUN_NAME}\" || true\nfi\n\n# idempotent non-interactive push with recovery\nif git push -u origin \"${BRANCH}\"; then\n  echo \"[ok] pushed ${BRANCH}\"\nelse\n  echo \"[warn] push rejected for ${BRANCH}; trying fetch+rebase+retry\"\n  git fetch origin \"${BRANCH}\" || true\n  git pull --rebase --autostash origin \"${BRANCH}\" || true\n  if git push -u origin \"${BRANCH}\"; then\n    echo \"[ok] pushed after rebase ${BRANCH}\"\n  else\n    FALLBACK=\"${BRANCH}-r$(date +%s)\"\n    echo \"[warn] retry failed; fallback branch ${FALLBACK}\"\n    git checkout -B \"${FALLBACK}\"\n    git push -u origin \"${FALLBACK}\"\n    BRANCH=\"${FALLBACK}\"\n    echo \"[ok] pushed fallback branch ${BRANCH}\"\n  fi\nfi\n\necho \"Create PR: https://github.com/seanwoory/MALTbot/compare/main...${BRANCH}?expand=1\"\n",
      "id": "jhrz6Wijrjgd"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}