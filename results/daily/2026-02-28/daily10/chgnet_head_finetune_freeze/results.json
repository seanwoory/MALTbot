{
  "experiment": "chgnet_head_finetune_freeze",
  "task": {
    "name": "matbench_mp_e_form"
  },
  "status": "success",
  "metric": 0.4674520023201592,
  "metric_name": "MAE",
  "metric_value": 0.4674520023201592,
  "metric_unit": "eV/atom",
  "fold_scores": {
    "0": 0.4674520023201592
  },
  "mean": 0.4674520023201592,
  "std": 0.0,
  "train_wall_time_sec": 832.271,
  "dataset_size": null,
  "num_params": null,
  "seed": 42,
  "model_config": "chgnet_head_finetune_freeze",
  "note": "CHGNet frozen backbone finetuning (ultra-fast smoke)",
  "exp_config_path": "configs/experiments/chgnet_head_finetune_freeze.yaml",
  "exp_params": {
    "epochs": 3,
    "lr": "1e-3",
    "freeze_backbone": true,
    "data_fraction": 0.1,
    "cache_fraction": 0.001,
    "early_stopping_patience": 3,
    "batch_size": 8,
    "folds": [
      "fold_0"
    ]
  },
  "output_path": "results/daily/2026-02-28/daily10/chgnet_head_finetune_freeze/results.json",
  "env": {
    "python": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]",
    "git_commit": "a2e3411fe6c36f9cfc298751a9321793c1802973",
    "torch": "2.10.0+cu128",
    "cuda_available": true,
    "gpu_type": "NVIDIA L4"
  },
  "effective_params": {
    "epochs": 3,
    "lr": "1e-3",
    "freeze_backbone": true,
    "data_fraction": 0.1,
    "cache_fraction": 0.001,
    "early_stopping_patience": 3,
    "batch_size": 8,
    "folds": [
      "fold_0"
    ]
  },
  "run": {
    "returncode": 0,
    "stdout_tail": "EFFECTIVE_CONFIG task=matbench_mp_e_form epochs=3 batch_size=8 lr=0.001 wd=0.0001 freeze_backbone=True mode=finetune train_fraction=0.1 val_fraction=0.1 early_stopping_patience=3\nUsing device: cuda\n2026-02-28 06:04:22 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n['matbench_mp_e_form']\n2026-02-28 06:04:22 INFO     Loading dataset 'matbench_mp_e_form'...\n2026-02-28 06:07:19 INFO     Dataset 'matbench_mp_e_form loaded.\n[cache] Using Google Drive cache root: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache\n[cache] chunk_size=1000 lru_chunks=30\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[WARN] cache_fraction(0.0010) < data_fraction(0.1000); auto-promoting cache_fraction to 0.1000\n[cache] agile cache_fraction=0.100: building subset cache only\nEFFECTIVE_CONFIG_EXT folds=[0] data_fraction=0.1 cache_fraction=0.1 cache_root=/content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache freeze_backbone=True\n[WARN] cache_root is on Drive; if epochs are slow, lower cache thrash with larger LRU/chunk-aware settings.\nBuilding/updating chunked graph cache (chunk_size=1000) ...\nChunked graph cache ready: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache/matbench_mp_e_form (new=0, adaptive=0, failed=0)\n\n--- Starting Fold: 0 ---\nEFFECTIVE_FOLD_DATA fold=0 n_train=10620 n_test=2655\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\nFreezing backbone (keeping readout/composition/mlp trainable)...\nEFFECTIVE_SPLIT n_train=955/9558 n_val=106/1062\n/usr/local/lib/python3.12/dist-packages/chgnet/model/model.py:898: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\nConsider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n  volumes = torch.tensor(volumes, dtype=TORCH_DTYPE, device=atomic_numbers.device)\nEpoch 1/3 - Loss: 2.175408 - Val MAE: 1.048275 - Time: 364.1s - ETA: 12.1 mins remaining for this fold\nEpoch 2/3 - Loss: 0.513205 - Val MAE: 0.664388 - Time: 97.5s - ETA: 3.8 mins remaining for this fold\nEpoch 3/3 - Loss: 0.300568 - Val MAE: 0.463241 - Time: 106.8s - ETA: 0.0 mins remaining for this fold\n[WARN] skip task.record for fold=0: data_fraction<1.0\nFold 0 MAE: 0.467452 (nan_ratio=0.00%)\n\nFinal mean MAE: 0.4674520023201592\nWrote results to results/daily/2026-02-28/daily10/chgnet_head_finetune_freeze/results.json\nFINAL_METRIC_MAE=0.467452",
    "stderr_tail": "EFFECTIVE_CONFIG task=matbench_mp_e_form epochs=3 batch_size=8 lr=0.001 wd=0.0001 freeze_backbone=True mode=finetune train_fraction=0.1 val_fraction=0.1 early_stopping_patience=3\nUsing device: cuda\n2026-02-28 06:04:22 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n['matbench_mp_e_form']\n2026-02-28 06:04:22 INFO     Loading dataset 'matbench_mp_e_form'...\n2026-02-28 06:07:19 INFO     Dataset 'matbench_mp_e_form loaded.\n[cache] Using Google Drive cache root: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache\n[cache] chunk_size=1000 lru_chunks=30\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[WARN] cache_fraction(0.0010) < data_fraction(0.1000); auto-promoting cache_fraction to 0.1000\n[cache] agile cache_fraction=0.100: building subset cache only\nEFFECTIVE_CONFIG_EXT folds=[0] data_fraction=0.1 cache_fraction=0.1 cache_root=/content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache freeze_backbone=True\n[WARN] cache_root is on Drive; if epochs are slow, lower cache thrash with larger LRU/chunk-aware settings.\nBuilding/updating chunked graph cache (chunk_size=1000) ...\nChunked graph cache ready: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache/matbench_mp_e_form (new=0, adaptive=0, failed=0)\n\n--- Starting Fold: 0 ---\nEFFECTIVE_FOLD_DATA fold=0 n_train=10620 n_test=2655\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\nFreezing backbone (keeping readout/composition/mlp trainable)...\nEFFECTIVE_SPLIT n_train=955/9558 n_val=106/1062\n/usr/local/lib/python3.12/dist-packages/chgnet/model/model.py:898: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\nConsider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n  volumes = torch.tensor(volumes, dtype=TORCH_DTYPE, device=atomic_numbers.device)\nEpoch 1/3 - Loss: 2.175408 - Val MAE: 1.048275 - Time: 364.1s - ETA: 12.1 mins remaining for this fold\nEpoch 2/3 - Loss: 0.513205 - Val MAE: 0.664388 - Time: 97.5s - ETA: 3.8 mins remaining for this fold\nEpoch 3/3 - Loss: 0.300568 - Val MAE: 0.463241 - Time: 106.8s - ETA: 0.0 mins remaining for this fold\n[WARN] skip task.record for fold=0: data_fraction<1.0\nFold 0 MAE: 0.467452 (nan_ratio=0.00%)\n\nFinal mean MAE: 0.4674520023201592\nWrote results to results/daily/2026-02-28/daily10/chgnet_head_finetune_freeze/results.json\nFINAL_METRIC_MAE=0.467452"
  },
  "source_output_path": "results/daily/2026-02-28/daily10/chgnet_head_finetune_freeze/results.json"
}