{
  "experiment": "chgnet_pretrained_infer",
  "task": {
    "name": "matbench_mp_e_form"
  },
  "status": "success",
  "metric": 4.918822448762227,
  "metric_name": "MAE",
  "metric_value": 4.918822448762227,
  "metric_unit": "eV/atom",
  "fold_scores": {
    "0": 4.918822448762227
  },
  "mean": 4.918822448762227,
  "std": 0.0,
  "train_wall_time_sec": 249.09,
  "dataset_size": null,
  "num_params": null,
  "seed": 42,
  "model_config": "chgnet_pretrained_infer",
  "note": "Zero-shot pretrained CHGNet inference (ultra-fast agile)",
  "exp_config_path": "configs/experiments/chgnet_pretrained_infer.yaml",
  "exp_params": {
    "epochs": 0,
    "mode": "pretrained",
    "data_fraction": 0.001,
    "cache_fraction": 0.001
  },
  "output_path": "results/daily/2026-02-28/daily10/chgnet_pretrained_infer/results.json",
  "env": {
    "python": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]",
    "git_commit": "0ac7ff7e13032c6826ca0d3545b81a802ecc3cf8",
    "torch": "2.10.0+cu128",
    "cuda_available": true,
    "gpu_type": "NVIDIA L4"
  },
  "effective_params": {
    "epochs": 0,
    "mode": "pretrained",
    "data_fraction": 0.001,
    "cache_fraction": 0.001
  },
  "run": {
    "returncode": 0,
    "stdout_tail": "EFFECTIVE_CONFIG task=matbench_mp_e_form epochs=0 batch_size=64 lr=0.001 wd=0.0001 freeze_backbone=False mode=finetune train_fraction=0.001 val_fraction=0.001 early_stopping_patience=5\nUsing device: cuda\n2026-02-28 06:00:10 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n['matbench_mp_e_form']\n2026-02-28 06:00:10 INFO     Loading dataset 'matbench_mp_e_form'...\nFetching matbench_mp_e_form.json.gz from https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz to /usr/local/lib/python3.12/dist-packages/matminer/datasets/matbench_mp_e_form.json.gz\n\nFetching https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz in MB:   0%|          | 0.0/166.734239 [00:00<?, ?MB/s]\nFetching https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz in MB:  46%|####5     | 75.948032/166.734239 [00:00<00:00, 759.45MB/s]\nFetching https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz in MB:  93%|#########3| 155.838464/166.734239 [00:00<00:00, 782.65MB/s]\nFetching https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz in MB: 166.735872MB [00:00, 754.73MB/s]                                \n2026-02-28 06:03:08 INFO     Dataset 'matbench_mp_e_form loaded.\n[cache] Using Google Drive cache root: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache\n[cache] chunk_size=1000 lru_chunks=30\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[cache] agile cache_fraction=0.001: building subset cache only\nEFFECTIVE_CONFIG_EXT folds=[0] data_fraction=0.001 cache_fraction=0.001 cache_root=/content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache freeze_backbone=False\n[WARN] cache_root is on Drive; if epochs are slow, lower cache thrash with larger LRU/chunk-aware settings.\nBuilding/updating chunked graph cache (chunk_size=1000) ...\nChunked graph cache ready: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache/matbench_mp_e_form (new=0, adaptive=0, failed=0)\n\n--- Starting Fold: 0 ---\nEFFECTIVE_FOLD_DATA fold=0 n_train=106 n_test=26\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[WARN] skip task.record for fold=0: data_fraction<1.0\nFold 0 MAE: 4.918822 (nan_ratio=0.00%)\n\nFinal mean MAE: 4.918822448762227\nWrote results to results/daily/2026-02-28/daily10/chgnet_pretrained_infer/results.json\nFINAL_METRIC_MAE=4.918822",
    "stderr_tail": "EFFECTIVE_CONFIG task=matbench_mp_e_form epochs=0 batch_size=64 lr=0.001 wd=0.0001 freeze_backbone=False mode=finetune train_fraction=0.001 val_fraction=0.001 early_stopping_patience=5\nUsing device: cuda\n2026-02-28 06:00:10 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n['matbench_mp_e_form']\n2026-02-28 06:00:10 INFO     Loading dataset 'matbench_mp_e_form'...\nFetching matbench_mp_e_form.json.gz from https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz to /usr/local/lib/python3.12/dist-packages/matminer/datasets/matbench_mp_e_form.json.gz\n\nFetching https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz in MB:   0%|          | 0.0/166.734239 [00:00<?, ?MB/s]\nFetching https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz in MB:  46%|####5     | 75.948032/166.734239 [00:00<00:00, 759.45MB/s]\nFetching https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz in MB:  93%|#########3| 155.838464/166.734239 [00:00<00:00, 782.65MB/s]\nFetching https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz in MB: 166.735872MB [00:00, 754.73MB/s]                                \n2026-02-28 06:03:08 INFO     Dataset 'matbench_mp_e_form loaded.\n[cache] Using Google Drive cache root: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache\n[cache] chunk_size=1000 lru_chunks=30\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[cache] agile cache_fraction=0.001: building subset cache only\nEFFECTIVE_CONFIG_EXT folds=[0] data_fraction=0.001 cache_fraction=0.001 cache_root=/content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache freeze_backbone=False\n[WARN] cache_root is on Drive; if epochs are slow, lower cache thrash with larger LRU/chunk-aware settings.\nBuilding/updating chunked graph cache (chunk_size=1000) ...\nChunked graph cache ready: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache/matbench_mp_e_form (new=0, adaptive=0, failed=0)\n\n--- Starting Fold: 0 ---\nEFFECTIVE_FOLD_DATA fold=0 n_train=106 n_test=26\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[WARN] skip task.record for fold=0: data_fraction<1.0\nFold 0 MAE: 4.918822 (nan_ratio=0.00%)\n\nFinal mean MAE: 4.918822448762227\nWrote results to results/daily/2026-02-28/daily10/chgnet_pretrained_infer/results.json\nFINAL_METRIC_MAE=4.918822"
  },
  "source_output_path": "results/daily/2026-02-28/daily10/chgnet_pretrained_infer/results.json"
}