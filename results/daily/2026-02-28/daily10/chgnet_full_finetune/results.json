{
  "experiment": "chgnet_full_finetune",
  "task": {
    "name": "matbench_mp_e_form"
  },
  "status": "success",
  "metric": 3.2813324124766363,
  "metric_name": "MAE",
  "metric_value": 3.2813324124766363,
  "metric_unit": "eV/atom",
  "fold_scores": {
    "0": 3.2813324124766363
  },
  "mean": 3.2813324124766363,
  "std": 0.0,
  "train_wall_time_sec": 539.75,
  "dataset_size": null,
  "num_params": null,
  "seed": 42,
  "model_config": "chgnet_full_finetune",
  "note": "Full CHGNet structure finetuning (ultra-fast agile)",
  "exp_config_path": "configs/experiments/chgnet_full_finetune.yaml",
  "exp_params": {
    "epochs": 3,
    "lr": "1e-4",
    "freeze_backbone": false,
    "data_fraction": 0.1,
    "cache_fraction": 0.001,
    "early_stopping_patience": 3,
    "batch_size": 8,
    "folds": [
      "fold_0"
    ]
  },
  "output_path": "results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json",
  "env": {
    "python": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]",
    "git_commit": "3f9c94a2298d658ce6360165e948118c98e4efd0",
    "torch": "2.10.0+cu128",
    "cuda_available": true,
    "gpu_type": "NVIDIA L4"
  },
  "effective_params": {
    "epochs": 3,
    "lr": "1e-4",
    "freeze_backbone": false,
    "data_fraction": 0.1,
    "cache_fraction": 0.001,
    "early_stopping_patience": 3,
    "batch_size": 8,
    "folds": [
      "fold_0"
    ]
  },
  "run": {
    "returncode": 0,
    "stdout_tail": "EFFECTIVE_CONFIG task=matbench_mp_e_form epochs=3 batch_size=8 lr=0.0001 wd=0.0001 freeze_backbone=False mode=finetune train_fraction=0.1 val_fraction=0.1 early_stopping_patience=3\nUsing device: cuda\n2026-02-28 06:18:18 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n['matbench_mp_e_form']\n2026-02-28 06:18:18 INFO     Loading dataset 'matbench_mp_e_form'...\n2026-02-28 06:21:15 INFO     Dataset 'matbench_mp_e_form loaded.\n[cache] Using Google Drive cache root: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache\n[cache] chunk_size=1000 lru_chunks=30\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[WARN] cache_fraction(0.0010) < data_fraction(0.1000); auto-promoting cache_fraction to 0.1000\n[cache] agile cache_fraction=0.100: building subset cache only\nEFFECTIVE_CONFIG_EXT folds=[0] data_fraction=0.1 cache_fraction=0.1 cache_root=/content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache freeze_backbone=False\n[WARN] cache_root is on Drive; if epochs are slow, lower cache thrash with larger LRU/chunk-aware settings.\nBuilding/updating chunked graph cache (chunk_size=1000) ...\nChunked graph cache ready: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache/matbench_mp_e_form (new=0, adaptive=0, failed=0)\n\n--- Starting Fold: 0 ---\nEFFECTIVE_FOLD_DATA fold=0 n_train=10620 n_test=2655\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\nEFFECTIVE_SPLIT n_train=955/9558 n_val=106/1062\n/usr/local/lib/python3.12/dist-packages/chgnet/model/model.py:898: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\nConsider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n  volumes = torch.tensor(volumes, dtype=TORCH_DTYPE, device=atomic_numbers.device)\nEpoch 1/3 - Loss: 4.078647 - Val MAE: 4.520433 - Time: 100.0s - ETA: 3.3 mins remaining for this fold\nEpoch 2/3 - Loss: 3.699705 - Val MAE: 4.055745 - Time: 98.5s - ETA: 1.7 mins remaining for this fold\nEpoch 3/3 - Loss: 3.141953 - Val MAE: 3.348337 - Time: 106.1s - ETA: 0.0 mins remaining for this fold\n[WARN] skip task.record for fold=0: data_fraction<1.0\nFold 0 MAE: 3.281332 (nan_ratio=0.00%)\n\nFinal mean MAE: 3.2813324124766363\nWrote results to results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json\nFINAL_METRIC_MAE=3.281332",
    "stderr_tail": "EFFECTIVE_CONFIG task=matbench_mp_e_form epochs=3 batch_size=8 lr=0.0001 wd=0.0001 freeze_backbone=False mode=finetune train_fraction=0.1 val_fraction=0.1 early_stopping_patience=3\nUsing device: cuda\n2026-02-28 06:18:18 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n['matbench_mp_e_form']\n2026-02-28 06:18:18 INFO     Loading dataset 'matbench_mp_e_form'...\n2026-02-28 06:21:15 INFO     Dataset 'matbench_mp_e_form loaded.\n[cache] Using Google Drive cache root: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache\n[cache] chunk_size=1000 lru_chunks=30\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[WARN] cache_fraction(0.0010) < data_fraction(0.1000); auto-promoting cache_fraction to 0.1000\n[cache] agile cache_fraction=0.100: building subset cache only\nEFFECTIVE_CONFIG_EXT folds=[0] data_fraction=0.1 cache_fraction=0.1 cache_root=/content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache freeze_backbone=False\n[WARN] cache_root is on Drive; if epochs are slow, lower cache thrash with larger LRU/chunk-aware settings.\nBuilding/updating chunked graph cache (chunk_size=1000) ...\nChunked graph cache ready: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache/matbench_mp_e_form (new=0, adaptive=0, failed=0)\n\n--- Starting Fold: 0 ---\nEFFECTIVE_FOLD_DATA fold=0 n_train=10620 n_test=2655\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\nEFFECTIVE_SPLIT n_train=955/9558 n_val=106/1062\n/usr/local/lib/python3.12/dist-packages/chgnet/model/model.py:898: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\nConsider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n  volumes = torch.tensor(volumes, dtype=TORCH_DTYPE, device=atomic_numbers.device)\nEpoch 1/3 - Loss: 4.078647 - Val MAE: 4.520433 - Time: 100.0s - ETA: 3.3 mins remaining for this fold\nEpoch 2/3 - Loss: 3.699705 - Val MAE: 4.055745 - Time: 98.5s - ETA: 1.7 mins remaining for this fold\nEpoch 3/3 - Loss: 3.141953 - Val MAE: 3.348337 - Time: 106.1s - ETA: 0.0 mins remaining for this fold\n[WARN] skip task.record for fold=0: data_fraction<1.0\nFold 0 MAE: 3.281332 (nan_ratio=0.00%)\n\nFinal mean MAE: 3.2813324124766363\nWrote results to results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json\nFINAL_METRIC_MAE=3.281332"
  },
  "source_output_path": "results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json"
}