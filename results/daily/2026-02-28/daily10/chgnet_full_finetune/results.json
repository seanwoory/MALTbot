{
  "experiment": "chgnet_full_finetune",
  "task": {
    "name": "matbench_mp_e_form"
  },
  "status": "success",
  "metric": 4.903081311404368,
  "metric_name": "MAE",
  "metric_value": 4.903081311404368,
  "metric_unit": "eV/atom",
  "fold_scores": {
    "0": 4.903081311404368
  },
  "mean": 4.903081311404368,
  "std": 0.0,
  "train_wall_time_sec": 200.097,
  "dataset_size": null,
  "num_params": null,
  "seed": 42,
  "model_config": "chgnet_full_finetune",
  "note": "Full CHGNet structure finetuning (ultra-fast agile)",
  "exp_config_path": "configs/experiments/chgnet_full_finetune.yaml",
  "exp_params": {
    "epochs": 2,
    "lr": "1e-4",
    "freeze_backbone": false,
    "data_fraction": 0.001,
    "cache_fraction": 0.001,
    "early_stopping_patience": 3
  },
  "output_path": "results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json",
  "env": {
    "python": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]",
    "git_commit": "70eed9f872f929a6db13b797261d41085223eb0d",
    "torch": "2.10.0+cu128",
    "cuda_available": true,
    "gpu_type": "NVIDIA L4"
  },
  "run": {
    "returncode": 0,
    "stdout_tail": "EFFECTIVE_CONFIG task=matbench_mp_e_form epochs=3 batch_size=8 lr=0.0001 wd=0.0001 freeze_backbone=False mode=finetune train_fraction=0.1 val_fraction=0.1 early_stopping_patience=3\nUsing device: cuda\n2026-02-28 04:43:12 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n['matbench_mp_e_form']\n2026-02-28 04:43:12 INFO     Loading dataset 'matbench_mp_e_form'...\n2026-02-28 04:46:08 INFO     Dataset 'matbench_mp_e_form loaded.\n[cache] Using Google Drive cache root: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache\n[cache] chunk_size=1000 lru_chunks=30\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[cache] agile cache_fraction=0.001: building subset cache only\nEFFECTIVE_CONFIG_EXT folds=[0] cache_fraction=0.001 cache_root=/content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache freeze_backbone=False\n[WARN] cache_root is on Drive; if epochs are slow, lower cache thrash with larger LRU/chunk-aware settings.\nBuilding/updating chunked graph cache (chunk_size=1000) ...\nChunked graph cache ready: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache/matbench_mp_e_form (new=0, adaptive=0, failed=0)\n\n--- Starting Fold: 0 ---\nEFFECTIVE_FOLD_DATA fold=0 n_train=106 n_test=26\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\nEFFECTIVE_SPLIT n_train=9/96 n_val=1/10\n/usr/local/lib/python3.12/dist-packages/chgnet/model/model.py:898: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\nConsider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n  volumes = torch.tensor(volumes, dtype=TORCH_DTYPE, device=atomic_numbers.device)\nEpoch 1/3 - Loss: 4.295918 - Val MAE: 3.391428 - Time: 5.3s - ETA: 0.2 mins remaining for this fold\nEpoch 2/3 - Loss: 4.286952 - Val MAE: 3.386929 - Time: 0.1s - ETA: 0.0 mins remaining for this fold\nEpoch 3/3 - Loss: 4.278171 - Val MAE: 3.382455 - Time: 0.1s - ETA: 0.0 mins remaining for this fold\n[WARN] skip task.record for fold=0: cache_fraction<1.0\nFold 0 MAE: 4.903081 (nan_ratio=0.00%)\n\nFinal mean MAE: 4.903081311404368\nWrote results to results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json\nFINAL_METRIC_MAE=4.903081",
    "stderr_tail": "EFFECTIVE_CONFIG task=matbench_mp_e_form epochs=3 batch_size=8 lr=0.0001 wd=0.0001 freeze_backbone=False mode=finetune train_fraction=0.1 val_fraction=0.1 early_stopping_patience=3\nUsing device: cuda\n2026-02-28 04:43:12 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n['matbench_mp_e_form']\n2026-02-28 04:43:12 INFO     Loading dataset 'matbench_mp_e_form'...\n2026-02-28 04:46:08 INFO     Dataset 'matbench_mp_e_form loaded.\n[cache] Using Google Drive cache root: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache\n[cache] chunk_size=1000 lru_chunks=30\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[cache] agile cache_fraction=0.001: building subset cache only\nEFFECTIVE_CONFIG_EXT folds=[0] cache_fraction=0.001 cache_root=/content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache freeze_backbone=False\n[WARN] cache_root is on Drive; if epochs are slow, lower cache thrash with larger LRU/chunk-aware settings.\nBuilding/updating chunked graph cache (chunk_size=1000) ...\nChunked graph cache ready: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache/matbench_mp_e_form (new=0, adaptive=0, failed=0)\n\n--- Starting Fold: 0 ---\nEFFECTIVE_FOLD_DATA fold=0 n_train=106 n_test=26\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\nEFFECTIVE_SPLIT n_train=9/96 n_val=1/10\n/usr/local/lib/python3.12/dist-packages/chgnet/model/model.py:898: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\nConsider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n  volumes = torch.tensor(volumes, dtype=TORCH_DTYPE, device=atomic_numbers.device)\nEpoch 1/3 - Loss: 4.295918 - Val MAE: 3.391428 - Time: 5.3s - ETA: 0.2 mins remaining for this fold\nEpoch 2/3 - Loss: 4.286952 - Val MAE: 3.386929 - Time: 0.1s - ETA: 0.0 mins remaining for this fold\nEpoch 3/3 - Loss: 4.278171 - Val MAE: 3.382455 - Time: 0.1s - ETA: 0.0 mins remaining for this fold\n[WARN] skip task.record for fold=0: cache_fraction<1.0\nFold 0 MAE: 4.903081 (nan_ratio=0.00%)\n\nFinal mean MAE: 4.903081311404368\nWrote results to results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json\nFINAL_METRIC_MAE=4.903081"
  },
  "source_output_path": "results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json"
}