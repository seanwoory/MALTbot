{
  "experiment": "chgnet_full_finetune",
  "task": {
    "name": "matbench_mp_e_form"
  },
  "status": "success",
  "metric": 4.910142655331018,
  "metric_name": "MAE",
  "metric_value": 4.910142655331018,
  "metric_unit": "eV/atom",
  "fold_scores": {
    "0": 4.910142655331018
  },
  "mean": 4.910142655331018,
  "std": 0.0,
  "train_wall_time_sec": 232.221,
  "dataset_size": null,
  "num_params": null,
  "seed": 42,
  "model_config": "chgnet_full_finetune",
  "note": "Full CHGNet structure finetuning (ultra-fast agile)",
  "exp_config_path": "configs/experiments/chgnet_full_finetune.yaml",
  "exp_params": {
    "epochs": 2,
    "lr": "1e-4",
    "freeze_backbone": false,
    "data_fraction": 0.001,
    "cache_fraction": 0.001,
    "early_stopping_patience": 3
  },
  "output_path": "results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json",
  "env": {
    "python": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]",
    "git_commit": "426d3dd6dd6d1cd0d33de40ecd95c17890ed7a4b",
    "torch": "2.10.0+cu128",
    "cuda_available": true,
    "gpu_type": "NVIDIA L4"
  },
  "run": {
    "returncode": 0,
    "stdout_tail": "EFFECTIVE_CONFIG task=matbench_mp_e_form epochs=3 batch_size=64 lr=0.0001 wd=0.0001 freeze_backbone=False mode=finetune train_fraction=0.1 val_fraction=0.1 early_stopping_patience=3\nUsing device: cuda\n2026-02-28 04:22:39 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n['matbench_mp_e_form']\n2026-02-28 04:22:39 INFO     Loading dataset 'matbench_mp_e_form'...\n2026-02-28 04:25:33 INFO     Dataset 'matbench_mp_e_form loaded.\n[cache] Using Google Drive cache root: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache\n[cache] chunk_size=1000 lru_chunks=30\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[cache] agile cache_fraction=0.001: building subset cache only\nEFFECTIVE_CONFIG_EXT folds=[0] cache_fraction=0.001 cache_root=/content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache freeze_backbone=False\n[WARN] cache_root is on Drive; if epochs are slow, lower cache thrash with larger LRU/chunk-aware settings.\nBuilding/updating chunked graph cache (chunk_size=1000) ...\nChunked graph cache ready: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache/matbench_mp_e_form (new=0, adaptive=0, failed=0)\n\n--- Starting Fold: 0 ---\nEFFECTIVE_FOLD_DATA fold=0 n_train=106 n_test=26\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\nEFFECTIVE_SPLIT n_train=9/96 n_val=1/10\n/usr/local/lib/python3.12/dist-packages/chgnet/model/model.py:898: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\nConsider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n  volumes = torch.tensor(volumes, dtype=TORCH_DTYPE, device=atomic_numbers.device)\nEpoch 1/3 - Loss: 4.163147 - Val MAE: 3.393650 - Time: 35.1s - ETA: 1.2 mins remaining for this fold\nEpoch 2/3 - Loss: 4.158832 - Val MAE: 3.391090 - Time: 0.1s - ETA: 0.3 mins remaining for this fold\nEpoch 3/3 - Loss: 4.154511 - Val MAE: 3.388527 - Time: 0.1s - ETA: 0.0 mins remaining for this fold\n[WARN] skip task.record for fold=0: cache_fraction<1.0\nFold 0 MAE: 4.910143 (nan_ratio=0.00%)\n\nFinal mean MAE: 4.910142655331018\nWrote results to results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json\nFINAL_METRIC_MAE=4.910143",
    "stderr_tail": "EFFECTIVE_CONFIG task=matbench_mp_e_form epochs=3 batch_size=64 lr=0.0001 wd=0.0001 freeze_backbone=False mode=finetune train_fraction=0.1 val_fraction=0.1 early_stopping_patience=3\nUsing device: cuda\n2026-02-28 04:22:39 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n['matbench_mp_e_form']\n2026-02-28 04:22:39 INFO     Loading dataset 'matbench_mp_e_form'...\n2026-02-28 04:25:33 INFO     Dataset 'matbench_mp_e_form loaded.\n[cache] Using Google Drive cache root: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache\n[cache] chunk_size=1000 lru_chunks=30\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\n[cache] agile cache_fraction=0.001: building subset cache only\nEFFECTIVE_CONFIG_EXT folds=[0] cache_fraction=0.001 cache_root=/content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache freeze_backbone=False\n[WARN] cache_root is on Drive; if epochs are slow, lower cache thrash with larger LRU/chunk-aware settings.\nBuilding/updating chunked graph cache (chunk_size=1000) ...\nChunked graph cache ready: /content/drive/MyDrive/MALTbot-cache/chgnet_graph_cache/matbench_mp_e_form (new=0, adaptive=0, failed=0)\n\n--- Starting Fold: 0 ---\nEFFECTIVE_FOLD_DATA fold=0 n_train=106 n_test=26\nCHGNet v0.3.0 initialized with 412,525 parameters\nCHGNet will run on cuda\nEFFECTIVE_SPLIT n_train=9/96 n_val=1/10\n/usr/local/lib/python3.12/dist-packages/chgnet/model/model.py:898: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\nConsider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n  volumes = torch.tensor(volumes, dtype=TORCH_DTYPE, device=atomic_numbers.device)\nEpoch 1/3 - Loss: 4.163147 - Val MAE: 3.393650 - Time: 35.1s - ETA: 1.2 mins remaining for this fold\nEpoch 2/3 - Loss: 4.158832 - Val MAE: 3.391090 - Time: 0.1s - ETA: 0.3 mins remaining for this fold\nEpoch 3/3 - Loss: 4.154511 - Val MAE: 3.388527 - Time: 0.1s - ETA: 0.0 mins remaining for this fold\n[WARN] skip task.record for fold=0: cache_fraction<1.0\nFold 0 MAE: 4.910143 (nan_ratio=0.00%)\n\nFinal mean MAE: 4.910142655331018\nWrote results to results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json\nFINAL_METRIC_MAE=4.910143"
  },
  "source_output_path": "results/daily/2026-02-28/daily10/chgnet_full_finetune/results.json"
}