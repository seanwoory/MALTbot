# MALTbot 일일 연구 전략 (2026-02-26)

## 1. 최근 성능 추이 요약 (최근 1~3일)
최근 RESULTS.md(2026-02-23 ~ 2026-02-25) 분석 결과, `mp_e_form` 타깃에 대해 제로샷 추론(`chgnet_pretrained_infer`)은 MAE 약 4.75를 기록하며 작동하고 있으나, 헤드 미세조정(`chgnet_head_finetune_freeze`) 및 전체 미세조정(`chgnet_full_finetune`) 실험에서 지속적으로 **ERROR**가 발생하고 있습니다. 기초 파이프라인(chgnet_baseline 등)은 아직 METRIC=None이거나 구현 오류 상태입니다.

## 2. 타깃 설정
기본 타깃인 **`mp_e_form`**에 계속 집중합니다. 현재 기초 미세조정(finetuning) 파이프라인에서 오류가 발생 중이므로, 이를 해결하는 것이 우선순위입니다. 다른 타깃(`mp_gap` 등)으로 전환하기보다는 파이프라인 안정화가 먼저 필요합니다.

## 3. Top-1 달성을 위한 '다음 24h' 최선 전략
**전략:** `chgnet_head_finetune_freeze` (Frozen Backbone Finetuning) 스크립트의 Error 원인 규명 및 수정

*   **왜:** 백본을 고정한 상태에서의 헤드 미세조정은 전체 미세조정보다 연산량이 적고 디버깅이 용이합니다. 이 단계가 성공해야 Full Finetuning으로 넘어갈 수 있습니다.
*   **리스크:** CHGNet의 Readout 및 AtomRef 레이어 구조에 대한 이해가 부족할 경우 수정 방향을 잘못 잡을 수 있으며, 파이토치 버전/의존성 충돌 문제일 가능성도 있습니다.
*   **실행단계:**
    1. 최근 실패한 `chgnet_head_finetune_freeze`의 로그 파일을 분석하여 에러 트레이스 확인.
    2. CHGNet 모델의 헤드(Readout) 교체 또는 Frozen 파라미터 설정(require_grad=False) 방식 점검 및 수정.
    3. 소규모 샘플로 빠른 테스트(smoke test) 진행하여 에러 해결 확인.

## 4. 오늘 AM/PM 2-run 계획
*변수 통제 원칙(1개 변수만 변경)*

*   **AM Run:** 헤드 레이어 파라미터 초기화 및 그라디언트 활성화 코드 수정본 테스트 (`chgnet_head_finetune_freeze` 디버그 런).
*   **PM Run:** AM Run 성공 시 학습률(Learning Rate) 스케줄러를 적용한 초기 에폭 학습 진행, 또는 AM Run 실패 시 에러 로그 기반의 데이터 로더/입력 텐서 형태 수정본 테스트.