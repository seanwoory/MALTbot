# 2026-02-21 15:00 KST — mp_e_form Top-1 가속 (Hourly Update)

## 0) 지금 상태 한 줄
- 오늘 daily10 결과를 보면 **레버(EMA/스케줄/타깃변환)는 아직 ‘실제로 적용’되지 않았고**, 실질적으로는 **seed만** 결과를 바꿨다. 지금 가장 급한 건 튜닝이 아니라 **(A) “full CHGNet finetune” 파이프라인 구현 + (B) 레버가 켜졌는지 검증 가능한 로깅/결과 경로 정리**다.

---

## 1) 레포(main) 최신 RESULTS.md + 최근 run 점검 (레버 적용 vs placeholder 분리)

### 1.1 RESULTS.md 최신 라인 관찰
- `2026-02-21 | matbench_mp_e_form | chgnet_baseline | METRIC=None` 형태로 기록됨.
- `chgnet_lr_schedule`, `chgnet_target_transform`, `chgnet_ema` 역시 **METRIC=None**이며 설명(note)에 **placeholder**로 명시.
- `alignn_baseline`, `kgcnn_schnet`, `kgcnn_dimenetpp`, `ensemble_3seed`, `chgnet_tta4`는 **SKIPPED / not implemented yet**.

근거: `RESULTS.md` tail(최신 40줄)

### 1.2 실제 점수는 어디에 있나? (중요한 파이프라인 사실)
- daily10 각 실험의 top-level `.../daily10/<exp>/results.json`은 `metric_value: null`일 수 있음.
- **실제 fold-mean 점수는** `.../daily10/2026-02-21/<exp>/results.json`에 저장되어 있음.

### 1.3 “실제로 적용된 레버”
- **Seed 변경만 적용됨**
  - baseline(seed=42): MAE mean **0.1112187908**
  - seed43: MAE mean **0.1087696994**
  - (이 차이는 꽤 큼: ~0.00245)

근거:
- `results/daily/2026-02-21/daily10/2026-02-21/baseline_chgnet/results.json`
- `results/daily/2026-02-21/daily10/2026-02-21/chgnet_seed43/results.json`

### 1.4 placeholder/미구현(= 점수 동일 또는 disabled)
- **placeholder (실제 레버 미적용; baseline과 점수 완전 동일)**
  - `chgnet_target_transform` (scores가 baseline과 동일)
  - `chgnet_lr_schedule` (scores가 baseline과 동일)
  - `chgnet_ema` (scores가 baseline과 동일)

근거:
- `results/daily/2026-02-21/daily10/2026-02-21/chgnet_target_transform/results.json`
- `results/daily/2026-02-21/daily10/2026-02-21/chgnet_lr_schedule/results.json`
- `results/daily/2026-02-21/daily10/2026-02-21/chgnet_ema/results.json`

- **미구현/disabled**
  - `alignn_baseline`: YAML에서 enabled:false로 스킵 (`error_message: Experiment disabled in YAML`)
  - `kgcnn_schnet`, `kgcnn_dimenetpp`, `ensemble_3seed`, `tta4`: not implemented / pipeline not implemented

근거:
- `results/daily/2026-02-21/daily10/alignn_baseline/results.json` 등

### 1.5 추가로 중요한 발견 (현재 모델이 ‘진짜 CHGNet’이 아님)
- scored 결과 파일의 `model.name`이 **"Route-B CHGNet-lite (composition MLP baseline)"**로 명시됨.
- 즉, 현재 파이프라인은 **full CHGNet finetune이 아니라 조성 기반 MLP 베이스라인**이며, Top-1(리더보드 0.0170)과는 구조적으로 큰 격차가 있음.

근거:
- `results/daily/2026-02-21/daily10/2026-02-21/baseline_chgnet/results.json`

---

## 2) 다음 24h 최적안 (실험 6개 이하)
> 제약: Colab 1회 세션에서 1~2시간 내 결과.  
> 따라서 “레이어/스케줄 튜닝” 전에 **(i) 레버 적용 여부 확인 가능한 빠른 프로토콜**, (ii) seed 분산 기준 확보가 우선.

### 2-a) 즉시 성능 올리는 레버 (구현이 이미 되어 있다면)
- 현실적으로 지금은 구현 미완(placeholder)이라 ‘즉시 성능’은 seed lucky-run 외엔 어렵다.
- **단, 즉시 할 수 있는 최적화 후보는 아래 2개**
  1) **seed sweep(3~4개)로 best seed 확보** (점수 즉시 개선 가능)
  2) **epochs 증가/감소로 underfit/overfit 방향 확인** (best_epoch 근처 찾기)

### 2-b) 파이프라인/모델 구현 레버 (Top-1 가속의 본체)
- 우선순위 1: **full CHGNet finetune(Structure 입력 기반)로 모델 교체**
  - 지금은 CHGNet-lite MLP라서 더 돌려도 Top-1이 아님.
- 우선순위 2: “레버가 켜졌는지”를 점수로 확인 가능한 최소 실험(예: y-standardize on/off) 구현
- 우선순위 3: ensemble/TTA는 나중(구현 후 성능 상향용)

### 2-c) 24h 내 실행 가능한 실험 6개(<=2h/세션 가정)
> 각 run은 ‘바꾸는 변수 1개’ 원칙. 단, 지금은 레버가 실제 미적용이라 **실험 목적이 ‘성능’보다 ‘진단’**임.

1) **Run#1: seed=44** (baseline 설정 동일)
   - 목적: seed 분산 스케일 추정(최소 3 seed)
2) **Run#2: seed=45**
   - 목적: best-seed 확보 + 분산 추가
3) **Run#3: epochs 40 → 80** (seed=best 고정)
   - 목적: underfit 여부 확인
4) **Run#4: weight_decay 1e-4 → 1e-3** (seed=best, epochs=best 고정)
   - 목적: 과적합/일반화 개선 여부 진단
5) **Run#5: dropout 0.1 → 0.0**
   - 목적: underfit이면 dropout 제거로 개선 가능
6) **Run#6: hidden_dim 256 → 512**
   - 목적: 용량 부족이면 개선, 아니면 시간만 증가

> 주의: 위 4~6번은 ‘모델이 MLP일 때’만 의미 있음. full CHGNet로 넘어가면 다시 재설계해야 함.

---

## 3) 다음 1시간 단위 업데이트에서 체크할 항목 (체크리스트)

### A. 결과 파일 정합성
- [ ] 새 run이 `daily10/<exp>/results.json`에만 남고, **`daily10/2026-02-21/<exp>/results.json`에 score가 저장되는지** 확인
- [ ] `RESULTS.md`가 METRIC=None로만 쌓이고 있는지(파이프라인 개선 필요 신호)

### B. 레버 적용 여부(placeholder 탐지)
- [ ] `chgnet_target_transform/lr_schedule/ema`가 baseline과 점수가 **완전 동일**인지(동일하면 아직 placeholder)
- [ ] config YAML 변경이 실제 실행 코드에 반영되는지(실험 1개로 확인)

### C. 성능 추세/노이즈
- [ ] seed 3개 이상 확보 후, mean±std를 계산해 “개선 컷라인” 설정(예: 0.001 이하 차이는 무시)
- [ ] max_error / rmse가 같이 개선되는지(꼬리 개선 여부)

### D. Top-1 가속의 본체 구현 상태
- [ ] CHGNet ‘진짜 finetune’(structure 기반)로 바뀌었는지: results.json의 `model.name`이 더 이상 CHGNet-lite MLP가 아닌지
- [ ] (가능하면) 학습 시간이 1~2h 안에 들어오도록 fold/epoch 전략이 정의됐는지

---

## 4) 결론 (왜 이게 최선인가)
1) 오늘 결과에서 **레버는 실제로 적용되지 않았고(seed만 효과)**라서, 레버 튜닝은 지금 하면 시간 낭비.
2) 현재 모델이 **CHGNet-lite MLP**여서 Top-1과 갭이 커, 다음 24h는 **모델/파이프라인 전환**이 가장 큰 레버.
3) 그 전 단계로, 1~2시간 내 가능한 **seed/epochs/정규화 진단 실험**으로 “노이즈 스케일”과 “학습 병목”을 확정하는 것이 가장 효율적.
